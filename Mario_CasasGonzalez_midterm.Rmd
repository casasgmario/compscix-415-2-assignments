---
title: "COMPSCIX 415.2 Homework 5/Midterm"
author: "Mario Casas Gonzalez"
date: "July 12, 2018"
output: 
  html_document:
    toc: TRUE
    theme: united 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


```


Hyperlink to my Github repository: https://github.com/casasgmario/compscix-415-2-assignments.git

## RStudio and R Markdown (3 points)

1. Use markdown headers in your document to clearly separate each midterm question and add a table of contents to your document.

## The tidyverse packages (3 points)

###1. Can you name which package is associated with each task below?

Plotting - 'ggplot2' is the enhanced data visualization package we have been using for the most part. The 'plot' verb is included in Base R graphics.  

Data munging/wrangling - 'dplyr' is the package intended for data manipulation, providing a consistent set of verbs that help you solve the most common data manipulation challenges such as mutate, select, filter, summarise and arrange. Overall, 'tidyr' helps tidy the data. 

Reshaping (spreading and gathering) data - this is included in the 'tidyr' package, part of the 'tidyverse' set. 

Importing/exporting data - the 'readr' package is used for importing and exporting data. 


###2. Now can you name two functions that you’ve used from each package that you listed above for these tasks?

Plotting - we have used 'ggplot', 'geom_point' and many other variations of 'geom_'
Data munging/wrangling - mutate, select, filter, summarise and arrange
Reshaping data - we have used 'gather()' and 'separate()'
Importing/exporting data - we've used 'read_delim' and 'write_csv'

```{r, warning = FALSE, message = FALSE}
library(tidyverse)
library(dplyr)
library(mdsr)
```


##R Basics (1.5 points) 

###1. Fix this code with the fewest number of changes possible so it works:

My_data.name___is.too00ooLong! <- c( 1 , 2 , 3 )

```{r R-Basics1, echo=TRUE}
My_data.name___is.too00ooLong <- c( 1 , 2 , 3 )

```

###2. Fix this code so it works:
my_string <- C('has', 'an', 'error', 'in', 'it)

```{r R-Basics2, echo=TRUE}
my_string <- c('has', 'an', 'error', 'in', 'it')

```

###3. Look at the code below and comment on what happened to the values in the vector.
my_vector <- c(1, 2, '3', '4', 5)
my_vector

What happened is that the values were stored as characters rather than numeric, because of the '' symbols in 3 and 4. 

```{r R-Basics3, echo=TRUE}
my_vector <- c(1, 2, '3', '4', 5)
is.character(my_vector)
my_vector <- c(1, 2, 3, 4, 5)
is.numeric(my_vector)

```

##Data import/export (3 points)

###1. Download the rail_trail.txt file from Canvas (in the Midterm Exam section) and successfully import it into R. Prove that it was imported successfully by including your import code and taking a glimpse of the result.

```{r DataImportExport1, echo=TRUE}
rail_trail <- read_delim('rail_trail.txt', delim = '|')
glimpse(rail_trail)
```

###2. Export the file into a comma-separated file and name it “rail_trail.csv”. Make sure you define the path correctly so that you know where it gets saved. Then reload the file. Include your export and import code and take another glimpse.

```{r DataImportExport2, echo=TRUE}
write_csv(rail_trail, 'rail_trail.csv')
rail_trail_csv <- read_csv('rail_trail.csv')
glimpse(rail_trail_csv)
```


##Visualization (6 points)

###1. Critique this graphic: give only three examples of what is wrong with this graphic. Be concise.

A) Poor and irrelevant use of color coding 
B) Not showing gender distribution per age group 
C) No % information shown 

###2. Reproduce this graphic using the diamonds data set.

```{r Visualization2, echo=TRUE}
ggplot(data = diamonds, mapping = aes(x = cut, y = carat, fill=color))+ geom_boxplot(position='identity') + coord_flip() + xlab("CUT OF DIAMOND") + ylab("CARAT OF DIAMOND")
```

### 3. The previous graphic is not very useful. We can make it much more useful by changing one thing about it. Make the change and plot it again.

```{r Visualization3, echo=TRUE}

ggplot(data = diamonds, mapping = aes(x = cut, y = carat, fill=color)) + geom_boxplot(position='identity', alpha=0.1) + coord_flip()

```

##Data munging and wrangling (6 points) 

###1. Is this data “tidy”? If yes, leave it alone and go to the next problem. If no, make it tidy. Note: this data set is called table2 and is available in the tidyverse package. It should be ready for you to use after you’ve loaded the tidyverse package.

```{r DatMunging1, echo=TRUE}
table2_scattered <- table2 %>% spread(key=type, value=count)
table2_scattered
```

###2 Create a new column in the diamonds data set called price_per_carat that shows the price of each diamond per carat (hint: divide). Only show me the code, not the output.

```{r DatMunging2, echo=TRUE}
diamonds_caratprice <- mutate(diamonds, price_per_carat=price/carat)

```

###3 For each cut of diamond in the diamonds data set, how many diamonds, and what proportion, have a price > 10000 and a carat < 1.5? There are several ways to get to an answer, but your solution must use the data wrangling verbs from the tidyverse in order to get credit. • Do the results make sense? Why? • Do we need to be wary of any of these numbers? Why?

Yes, the results show a correlation between the quality of the cut and the number of small, expensive diamonds. We need to be wary because we are leaving out other variables such as color, so the analysis is not complete. 




```{r DatMunging3, echo=TRUE}
diamonds_expensive_small <- diamonds %>% filter(price>1000 & carat < 1.5)
diamonds_expensive_small <- diamonds_expensive_small %>% group_by(cut) %>% summarize(count=n())
mutate(diamonds_expensive_small,proportion=count/(sum(diamonds_expensive_small$count)))
```

##EDA (6 points)

### Take a look at the txhousing data set that is included with the ggplot2 package and answer these questions:


1. During what time period is this data from?

2000 to 2015. 

2. How many cities are represented?

46 cities. 

3. Which city, month and year had the highest number of sales?

Houston, June, 2006

4. What kind of relationship do you think exists between the number of listings and the number of sales?

There should be a direct correlation between the number of listings and the number of sales. 

Check your assumption and show your work.

5. What proportion of sales is missing for each city?

Per output above. 

6. Looking at only the cities and months with greater than 500 sales:
• Are the distributions of the median sales price (column name median), when grouped by city, different? The same? Show your work. 
• Any cities that stand out that you’d want to investigate further? > 
• Why might we want to filter out all cities and months with sales less than 500? > Because they belong to rural areas, where the market is different. 

```{r EDA, echo=TRUE}
txhousing %>% group_by(year) %>% summarize (count=n())
txhousing %>% group_by(city) %>% summarize (count=n())
txhousing %>% filter(!is.na(sales)) %>% group_by(city) %>% tally (sales, sort="TRUE")
txhousing %>% filter(!is.na(sales)) %>% group_by(year) %>% tally (sales, sort="TRUE")
ggplot(data=txhousing, mapping=aes(x=listings, y=sales)) +geom_point()
(sales_lm <- lm(formula = listings ~ sales, data = txhousing))
missing_sales <- txhousing %>% filter(is.na(sales))
missing_sales %>% group_by(city) %>% summarize(count=n())
txhousing %>% group_by(city) %>% ggplot() + geom_histogram(aes(x=median))
txhousing %>% ggplot() + geom_histogram(aes(x=median))

```




## Git and Github (1.5 points)

### To demonstrate your use of git and Github, at the top of your document put a hyperlink to your Github repository.
